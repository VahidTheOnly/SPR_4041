\documentclass[12pt,a4paper]{article}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{margin=2.5cm}
\usepackage{booktabs}
\usepackage{url}
\usepackage{float}
\usepackage{caption}
\usepackage{listings}
\usepackage{xcolor}

\usepackage{xepersian}
\settextfont[Scale=1.1]{Amiri}
\setlatintextfont{Times New Roman}

\title{\textbf{تکلیف کامپیوتری چهارم - درس شناسایی الگو}}
\author{وحید ملکی \\ شماره دانشجویی: 40313004}
\date{\today}

\begin{document}
	
	\maketitle
	
	\section{مقدمه و آماده‌سازی داده‌ها}
	در این تکلیف، هدف پیاده‌سازی و ارزیابی ماشین بردار پشتیبان (\lr{SVM}) بر روی مجموعه داده \lr{Fashion-MNIST} است. این مجموعه داده شامل تصاویر $28 \times 28$ پیکسلی از پوشاک در $10$ کلاس مختلف است. به دلیل حجم بالای داده‌ها و محدودیت‌های محاسباتی در پیاده‌سازی دستی، از یک زیرمجموعه شامل $2000$ نمونه استفاده شد.
	ابتدا داده‌ها بارگذاری شده و به طور تصادفی مخلوط (\lr{Shuffle}) شدند. سپس $20$ درصد از داده‌ها (معادل $400$ نمونه) به عنوان داده‌های آزمون (\lr{Test Set}) و $80$ درصد باقی‌مانده (معادل $1600$ نمونه) به عنوان داده‌های آموزش (\lr{Train Set}) جدا شدند. برای بهبود عملکرد الگوریتم‌های مبتنی بر گرادیان، داده‌ها نرمال‌سازی شدند تا میانگین صفر و واریانس یک داشته باشند.
	
	\section{پیاده‌سازی مدل \lr{SVM} با استفاده از \lr{NumPy}}
	در بخش اول، الگوریتم \lr{SVM} بدون استفاده از کتابخانه‌های آماده و صرفاً با استفاده از جبر خطی در \lr{NumPy} پیاده‌سازی شد.
	
	\subsection{ریاضیات و منطق کلاس \lr{SVMScratch}}
	این کلاس هسته اصلی الگوریتم را تشکیل می‌دهد و برای حل مسأله بهینه‌سازی \lr{SVM} از روش «گرادیان صعودی» (\lr{Gradient Ascent}) بر روی فرم دوگان (\lr{Dual Form}) استفاده می‌کند.
	
	\subsubsection{تابع \lr{\_kernel}}
	این تابع وظیفه محاسبه ماتریس کرنل (شباهت بین نمونه‌ها) را بر عهده دارد. دو نوع کرنل پیاده‌سازی شد:
	\begin{itemize}
		\item \textbf{کرنل خطی (\lr{Linear}):} به صورت ضرب داخلی دو بردار ویژگی تعریف می‌شود:
		\begin{equation}
			K(x_i, x_j) = x_i^T x_j
		\end{equation}
		\item \textbf{کرنل \lr{RBF}:} که بر اساس فاصله اقلیدسی عمل می‌کند و قابلیت جداسازی غیرخطی را فراهم می‌آورد:
		\begin{equation}
			K(x_i, x_j) = \exp(-\gamma ||x_i - x_j||^2)
		\end{equation}
	\end{itemize}
	
	\subsubsection{تابع \lr{fit}}
	این تابع ضرایب لاگرانژ ($\alpha$) را یاد می‌گیرد. هدف ما بیشینه‌سازی تابع هدف دوگان است:
	\begin{equation}
		L(\alpha) = \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j K(x_i, x_j)
	\end{equation}
	مشتق این تابع نسبت به $\alpha$ برابر است با:
	\begin{equation}
		\nabla L = 1 - y_i \sum_{j=1}^{n} \alpha_j y_j K(x_i, x_j)
	\end{equation}
	در حلقه یادگیری، مقادیر $\alpha$ با نرخ یادگیری (\lr{lr}) در جهت گرادیان به‌روزرسانی می‌شوند. همچنین شرط محدودیت جعبه‌ای ($0 \le \alpha \le C$) با استفاده از تابع \lr{clip} اعمال می‌شود. در نهایت، مقدار بایاس ($b$) با استفاده از بردارهای پشتیبان (نقاطی که $0 < \alpha < C$) محاسبه می‌شود.
	
	\subsubsection{تابع \lr{decision\_function}}
	برای پیش‌بینی امتیاز یک نمونه جدید $x$، از رابطه زیر استفاده می‌شود:
	\begin{equation}
		f(x) = \sum_{i \in SV} \alpha_i y_i K(x_i, x) + b
	\end{equation}
	این مقدار نشان‌دهنده فاصله نمونه تا ابرصفحه جداکننده است.
	
	\subsection{استراتژی چندکلاسه و ارزیابی}
	از آنجا که \lr{SVM} ذاتاً یک طبقه‌بند باینری است، برای مسأله ۱۰ کلاسه از استراتژی «یکی در برابر بقیه» (\lr{One-vs-Rest}) در تابع \lr{train\_svm} استفاده شد. به ازای هر کلاس، یک مدل آموزش داده می‌شود که آن کلاس را $+1$ و سایرین را $-1$ در نظر می‌گیرد.
	تابع \lr{predict} خروجی تمام ۱۰ مدل را دریافت کرده و کلاسی که بیشترین امتیاز (بیشترین فاصله مثبت از مرز تصمیم) را داشته باشد، به عنوان برچسب نهایی انتخاب می‌کند (\lr{argmax}).
	
	\subsection{اعتبارسنجی متقاطع (\lr{Cross-Validation})}
	برای انتخاب بهترین فراپارامترها، از روش $10$-\lr{Fold Cross-Validation} استفاده شد. تابع \lr{get\_k\_folds} داده‌های آموزش را به ۱۰ بخش مساوی تقسیم می‌کند. نتایج میانگین دقت برای مقادیر مختلف $C$ و کرنل‌ها به شرح زیر به دست آمد:
	
	\begin{itemize}
		\item \textbf{کرنل خطی (\lr{Linear}):} همان‌طور که مشاهده می‌شود، دقت در تمامی مقادیر $C$ بسیار پایین (حدود $16\%$) است.
		\begin{lstlisting}[basicstyle=\ttfamily\small, frame=single]
			C=0.01 => 17.19% | C=0.1 => 14.75% | C=1 => 16.25% 
			C=10 => 16.56%   | C=100 => 16.25%
		\end{lstlisting}
		\textbf{تحلیل عملکرد ضعیف خطی:} دلیل اصلی این عملکرد ضعیف در پیاده‌سازی دستی، ماهیت الگوریتم گرادیان صعودی ساده است. در فضای ویژگی‌های با ابعاد بالا ($784$ بعد)، سطح خطای کرنل خطی بسیار ناهموار است و الگوریتم گرادیان ساده بدون اعمال دقیق شرط تساوی ($\sum \alpha_i y_i = 0$) و بدون استفاده از روش‌های پیشرفته‌تر مانند \lr{SMO} یا \lr{Coordinate Descent}، نمی‌تواند همگرا شود و دچار نوسان می‌شود.
		
		\item \textbf{کرنل \lr{RBF}:} عملکرد بسیار بهتری نشان داد و با افزایش $C$ دقت بهبود یافت.
		\begin{lstlisting}[basicstyle=\ttfamily\small, frame=single]
			C=0.01 => 71.06% | C=0.1 => 76.50% | C=1 => 81.63%
			C=10 => 83.06%   | C=100 => 83.06%
		\end{lstlisting}
	\end{itemize}
	
	% محل قرارگیری تصویر اول
	 \begin{figure}[H]
		 	\centering
		 	\includegraphics[width=0.8\textwidth]{numpy_results.png}
		 	\caption{نمودار تغییرات دقت بر حسب مقدار C در پیاده‌سازی دستی (NumPy)}
		 	\label{fig:numpy_results}
		 \end{figure}
	
	\subsection{نتیجه نهایی مدل \lr{NumPy}}
	بهترین پارامترهای یافت شده عبارتند از \lr{kernel='rbf'} و $C=10$ که دقت اعتبارسنجی $83.06\%$ را داشت. پس از آموزش مجدد مدل با این پارامترها روی کل داده‌های آموزش، دقت نهایی روی داده‌های آزمون برابر با \textbf{$81.61\%$} به دست آمد.
	
	\section{پیاده‌سازی با استفاده از \lr{Scikit-Learn}}
	در این بخش از کتابخانه استاندارد \lr{sklearn} برای پیاده‌سازی استفاده شد که از حل‌گر قدرتمند \lr{LibSVM} استفاده می‌کند.
	
	\subsection{اجزای استفاده شده}
	\begin{itemize}
		\item \textbf{\lr{StandardScaler}:} برای نرمال‌سازی داده‌ها (میانگین صفر و انحراف معیار یک) استفاده شد که تأثیر بسزایی در همگرایی \lr{SVM} دارد.
		\item \textbf{\lr{OneVsRestClassifier}:} این کلاس به صورت خودکار استراتژی یکی در برابر بقیه را برای مسائل چندکلاسه مدیریت می‌کند.
		\item \textbf{\lr{StratifiedKFold}:} برخلاف تقسیم تصادفی ساده، این روش تضمین می‌کند که نسبت کلاس‌ها در هر \lr{Fold} حفظ شود که برای داده‌های غیرمتوازن حیاتی است.
		\item \textbf{\lr{GridSearchCV}:} جستجوی شبکه‌ای برای یافتن بهترین ترکیب فراپارامترها ($C$ و نوع کرنل) همراه با اعتبارسنجی متقاطع.
	\end{itemize}
	
	\subsection{تحلیل نتایج \lr{Scikit-Learn}}
	نتایج جستجوی شبکه‌ای نشان داد که پیاده‌سازی کتابخانه‌ای رفتار پایدارتری دارد. نمودار دقت بر حسب پارامتر $C$ در شکل زیر (در صورت فعال‌سازی) قابل مشاهده است. نکته قابل توجه این است که در پیاده‌سازی \lr{sklearn}، کرنل خطی نیز عملکرد قابل قبولی دارد، اما همچنان کرنل \lr{RBF} برتری دارد.
	
	% محل قرارگیری تصویر دوم (یکی از دو تصویر مشابه مربوط به sklearn)
	 \begin{figure}[H]
		 	\centering
		 	\includegraphics[width=0.8\textwidth]{sklearn_results.png}
		 	\caption{نمودار تغییرات دقت بر حسب مقدار C در پیاده‌سازی Scikit-Learn}
		 	\label{fig:sklearn_results}
		 \end{figure}
	
	بهترین مدل در این حالت نیز با پارامترهای $C=10$ و کرنل \lr{RBF} به دست آمد که دقت اعتبارسنجی آن $83.38\%$ بود. دقت نهایی روی داده‌های آزمون برابر با \textbf{$82.50\%$} شد.
	
	\section{مقایسه و نتیجه‌گیری}
	مقایسه نتایج نهایی نشان می‌دهد که پیاده‌سازی دستی ما با وجود سادگی، عملکرد بسیار نزدیکی به کتابخانه بهینه‌شده \lr{Scikit-Learn} دارد ($81.61\%$ در مقابل $82.50\%$).
	
	\subsection{تحلیل گزارش کلاس‌بندی (\lr{Classification Report})}
	با مقایسه گزارش‌های کلاس‌بندی هر دو مدل، نتایج زیر حاصل می‌شود:
	\begin{itemize}
		\item \textbf{کلاس‌های موفق:} هر دو مدل در تشخیص کلاس $1$ (شلوار) و کلاس $9$ (کفش ساق‌دار) بسیار عالی عمل کرده‌اند (دقت بالای $95\%$). این نشان می‌دهد ویژگی‌های این کلاس‌ها تمایز بالایی دارند.
		\item \textbf{کلاس‌های چالش‌برانگیز:} کلاس $6$ (پیراهن) در هر دو مدل کمترین دقت را داشته است (\lr{Recall} حدود $0.55$). این کلاس به دلیل شباهت ظاهری زیاد به تی‌شرت (کلاس $0$) و پلوشرت (کلاس $2$)، بیشترین خطا را ایجاد کرده است.
		\item \textbf{پایداری:} مدل \lr{Scikit-Learn} در کلاس‌های دشوار کمی متعادل‌تر عمل کرده است، اما الگوی خطاها در هر دو مدل یکسان است که نشان‌دهنده ماهیت داده‌هاست.
	\end{itemize}
	
	در جدول زیر گزارش نهایی مدل \lr{Scikit-Learn} آورده شده است:
	
	\begin{table}[H]
		\centering
		\caption{گزارش کلاس‌بندی نهایی (بهترین مدل)}
		\begin{latin}
			\begin{tabular}{ccccc}
				\toprule
				\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
				\midrule
				0 & 0.65 & 0.80 & 0.72 & 40 \\
				1 & 1.00 & 0.93 & 0.96 & 40 \\
				2 & 0.71 & 0.72 & 0.72 & 40 \\
				3 & 0.88 & 0.70 & 0.78 & 40 \\
				4 & 0.74 & 0.85 & 0.79 & 40 \\
				5 & 0.92 & 0.88 & 0.90 & 40 \\
				6 & 0.67 & 0.55 & 0.60 & 40 \\
				7 & 0.95 & 0.90 & 0.92 & 40 \\
				8 & 0.83 & 0.97 & 0.90 & 40 \\
				9 & 0.97 & 0.95 & 0.96 & 40 \\
				\midrule
				\textbf{Accuracy} & & & \textbf{0.82} & 400 \\
				\bottomrule
			\end{tabular}
		\end{latin}
	\end{table}
	
\end{document}