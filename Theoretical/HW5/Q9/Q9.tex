\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{xepersian}
\settextfont{Amiri}
\setlatintextfont{Times New Roman}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{enumitem}
\geometry{margin=2.5cm}

\title{تکلیف پنجم درس شناسایی الگو}
\author{وحید ملکی \\ شماره دانشجویی: 40313004}
\date{\today}

\begin{document}
	
	\maketitle
	
	\section*{سؤال ۹}
	
	در این مسئله، هدف طراحی یک طبقه‌بند برای پیش‌بینی جنسیت فرد (\(G\)) بر اساس دو ویژگی وزن (\(W\)) و وضعیت فارغ‌التحصیلی (\(S\)) است.  
	فرض شده است:
	\begin{itemize}
		\item \(W\) و \(S\) از یکدیگر \textbf{مستقل} هستند.
		\item واریانس توزیع \(P(W \mid G = \text{female})\) و \(P(W \mid G = \text{male})\) برابر است.
		\item \(G \in \{\text{male}, \text{female}\}\)
		\item \(W\): متغیر پیوسته
		\item \(S \in \{0, 1\}\): متغیر باینری
	\end{itemize}
	
	\subsection*{الف) آیا استفاده از طبقه‌بند Naïve Bayes مناسب است؟}
	
	\textbf{بله}، استفاده از طبقه‌بند \textbf{Naïve Bayes} در این مسئله کاملاً مناسب و منطقی است.
	
	دلیل:
	طبقه‌بند Naïve Bayes بر پایه فرض \textbf{استقلال شرطی ویژگی‌ها نسبت به کلاس} بنا شده است، یعنی:
	\[
	P(W, S \mid G = g) = P(W \mid G = g) \cdot P(S \mid G = g)
	\]
	در این مسئله \textbf{صراحتاً} گفته شده که \(W\) و \(S\) \textbf{از یکدیگر مستقل هستند}. این فرض دقیقاً با اصل اساسی Naïve Bayes هم‌خوانی دارد.  
	بنابراین، این روش نه تنها مجاز، بلکه \textbf{انتخاب بهینه و کارآمد} است.
	
	قانون طبقه‌بندی به صورت زیر است:
	\[
	\hat{G} = \arg\max_{g \in \{\text{male}, \text{female}\}} P(G = g \mid W, S)
	\]
	با استفاده از قضیه بیز:
	\[
	P(G = g \mid W, S) \propto P(W, S \mid G = g) \cdot P(G = g)
	\]
	و با اعمال فرض استقلال (naïve):
	\[
	P(W, S \mid G = g) = P(W \mid G = g) \cdot P(S \mid G = g)
	\]
	
	\subsection*{ب) توزیع‌های احتمالی مورد نیاز و تعداد پارامترها}
	
	از آنجا که استفاده از Naïve Bayes مناسب است، توزیع‌های زیر باید از داده‌های آموزشی تخمین زده شوند:
	
	\subsubsection*{۱. توزیع پیشین \(P(G)\)}
	\begin{itemize}
		\item \(P(G = \text{male})\)
		\item \(P(G = \text{female}) = 1 - P(G = \text{male})\)
	\end{itemize}
	\textbf{تعداد پارامتر}: \(1\)
	
	\subsubsection*{۲. توزیع شرطی وزن \(P(W \mid G)\)}
	متغیر \(W\) پیوسته است → مدل‌سازی با توزیع \textbf{گوسی} برای هر کلاس:
	\[
	P(W \mid G = \text{male}) \sim \mathcal{N}(\mu_{\text{male}}, \sigma_W^2), \quad
	P(W \mid G = \text{female}) \sim \mathcal{N}(\mu_{\text{female}}, \sigma_W^2)
	\]
	(واریانس مشترک \(\sigma_W^2\) طبق فرض مسئله)
	
	\textbf{پارامترها}:
	\begin{itemize}
		\item \(\mu_{\text{male}}\)
		\item \(\mu_{\text{female}}\)
		\item \(\sigma_W^2\) (مشترک)
	\end{itemize}
	\textbf{تعداد پارامتر}: \(3\)
	
	\subsubsection*{۳. توزیع شرطی وضعیت فارغ‌التحصیلی \(P(S \mid G)\)}
	متغیر \(S\) باینری است → مدل‌سازی با توزیع \textbf{برنولی} برای هر کلاس:
	\begin{itemize}
		\item \(\theta_{S|\text{male}} = P(S=1 \mid G = \text{male})\)
		\item \(\theta_{S|\text{female}} = P(S=1 \mid G = \text{female})\)
	\end{itemize}
	(احتمال \(S=0\) مکمل است)
	
	\textbf{تعداد پارامتر}: \(2\)
	
	\subsubsection*{جمع کل پارامترها}
	\[
	\boxed{1 + 3 + 2 = 6}
	\]
	
	\begin{center}
		\begin{tabular}{|c|l|c|}
			\hline
			\textbf{توزیع} & \textbf{پارامترها} & \textbf{تعداد} \\
			\hline
			\(P(G)\) & \(P(G=\text{male})\) & 1 \\
			\hline
			\(P(W \mid G)\) & \(\mu_{\text{male}}, \mu_{\text{female}}, \sigma_W^2\) & 3 \\
			\hline
			\(P(S \mid G)\) & \(\theta_{S|\text{male}}, \theta_{S|\text{female}}\) & 2 \\
			\hline
			\multicolumn{2}{|c|}{\textbf{مجموع}} & \textbf{6} \\
			\hline
		\end{tabular}
	\end{center}
	
	در نتیجه، طبقه‌بند Naïve Bayes با \textbf{۶ پارامتر} کاملاً قابل آموزش است و با فرضیات مسئله سازگار است.
	
\end{document}